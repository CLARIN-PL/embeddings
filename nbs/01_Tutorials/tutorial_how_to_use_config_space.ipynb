{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "633a339d",
   "metadata": {},
   "source": [
    "# How to use our configs? \n",
    "\n",
    "> Detailed tutorial about how to pass arguments to embeddings pipelines.\n",
    "\n",
    "- title-block-banner: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4618b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.qmd import *\n",
    "import warnings\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f61c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# disable HF thousand warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# set os environ variable for multiprocesses\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ab00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from embeddings.config.lightning_config import (\n",
    "    LightningAdvancedConfig,\n",
    "    LightningBasicConfig,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4999e8c8",
   "metadata": {},
   "source": [
    "Two types of config are defined in our library: `BasicConfig` and `AdvancedConfig`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0451fe7",
   "metadata": {},
   "source": [
    "## BasicConfig\n",
    "\n",
    "> allows for easy use of the most common parameters in the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8de07b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningBasicConfig\n",
       "\n",
       ">      LightningBasicConfig (use_scheduler:bool=True, optimizer:str='Adam',\n",
       ">                            warmup_steps:int=100, learning_rate:float=0.0001,\n",
       ">                            adam_epsilon:float=1e-08, weight_decay:float=0.0,\n",
       ">                            finetune_last_n_layers:int=-1,\n",
       ">                            classifier_dropout:Optional[float]=None,\n",
       ">                            max_seq_length:Optional[int]=None,\n",
       ">                            batch_size:int=32, max_epochs:Optional[int]=None,\n",
       ">                            early_stopping_monitor:str='val/Loss',\n",
       ">                            early_stopping_mode:str='min',\n",
       ">                            early_stopping_patience:int=3)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningBasicConfig\n",
       "\n",
       ">      LightningBasicConfig (use_scheduler:bool=True, optimizer:str='Adam',\n",
       ">                            warmup_steps:int=100, learning_rate:float=0.0001,\n",
       ">                            adam_epsilon:float=1e-08, weight_decay:float=0.0,\n",
       ">                            finetune_last_n_layers:int=-1,\n",
       ">                            classifier_dropout:Optional[float]=None,\n",
       ">                            max_seq_length:Optional[int]=None,\n",
       ">                            batch_size:int=32, max_epochs:Optional[int]=None,\n",
       ">                            early_stopping_monitor:str='val/Loss',\n",
       ">                            early_stopping_mode:str='min',\n",
       ">                            early_stopping_patience:int=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningBasicConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8cd79",
   "metadata": {},
   "source": [
    "## AdvancedConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e068ed63",
   "metadata": {},
   "source": [
    "> the objects defined in our pipelines are constructed in a way that they can be further paramatrized with keyword arguments. These arguments can be utilized by constructing the `AdvancedConfig`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f004815e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningAdvancedConfig\n",
       "\n",
       ">      LightningAdvancedConfig (finetune_last_n_layers:int,\n",
       ">                               task_model_kwargs:Dict[str,Any],\n",
       ">                               datamodule_kwargs:Dict[str,Any],\n",
       ">                               task_train_kwargs:Dict[str,Any],\n",
       ">                               model_config_kwargs:Dict[str,Any],\n",
       ">                               early_stopping_kwargs:Dict[str,Any],\n",
       ">                               tokenizer_kwargs:Dict[str,Any],\n",
       ">                               batch_encoding_kwargs:Dict[str,Any],\n",
       ">                               dataloader_kwargs:Dict[str,Any])"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningAdvancedConfig\n",
       "\n",
       ">      LightningAdvancedConfig (finetune_last_n_layers:int,\n",
       ">                               task_model_kwargs:Dict[str,Any],\n",
       ">                               datamodule_kwargs:Dict[str,Any],\n",
       ">                               task_train_kwargs:Dict[str,Any],\n",
       ">                               model_config_kwargs:Dict[str,Any],\n",
       ">                               early_stopping_kwargs:Dict[str,Any],\n",
       ">                               tokenizer_kwargs:Dict[str,Any],\n",
       ">                               batch_encoding_kwargs:Dict[str,Any],\n",
       ">                               dataloader_kwargs:Dict[str,Any])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningAdvancedConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff37863",
   "metadata": {},
   "source": [
    "  \n",
    "In summary, the `BasicConfig` takes arguments and automatically assign them into proper keyword group, while the `AdvancedConfig` takes as the input keyword groups that should be already correctly mapped.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca06ba6",
   "metadata": {},
   "source": [
    "\n",
    "The list of available config can be found below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f430f11f",
   "metadata": {},
   "source": [
    "## Running pipeline with BasicConfig\n",
    "\n",
    "Let's run example pipeline on `polemo2` dataset\n",
    "\n",
    "But first we downsample our dataset due to hardware limitations for that purpose we use HuggingFacePreprocessingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "286a7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exec_doc\n",
    "from embeddings.pipeline.hf_preprocessing_pipeline import HuggingFacePreprocessingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf41e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### HuggingFacePreprocessingPipeline\n",
       "\n",
       ">      HuggingFacePreprocessingPipeline (dataset_name:str, persist_path:str, sam\n",
       ">                                        ple_missing_splits:Optional[Tuple[Optio\n",
       ">                                        nal[float],Optional[float]]]=None, down\n",
       ">                                        sample_splits:Optional[Tuple[Optional[f\n",
       ">                                        loat],Optional[float],Optional[float]]]\n",
       ">                                        =None, ignore_test_subset:bool=False,\n",
       ">                                        seed:int=441, load_dataset_kwargs:Optio\n",
       ">                                        nal[Dict[str,Any]]=None)\n",
       "\n",
       "Preprocessing pipeline dedicated to work with HuggingFace datasets."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### HuggingFacePreprocessingPipeline\n",
       "\n",
       ">      HuggingFacePreprocessingPipeline (dataset_name:str, persist_path:str, sam\n",
       ">                                        ple_missing_splits:Optional[Tuple[Optio\n",
       ">                                        nal[float],Optional[float]]]=None, down\n",
       ">                                        sample_splits:Optional[Tuple[Optional[f\n",
       ">                                        loat],Optional[float],Optional[float]]]\n",
       ">                                        =None, ignore_test_subset:bool=False,\n",
       ">                                        seed:int=441, load_dataset_kwargs:Optio\n",
       ">                                        nal[Dict[str,Any]]=None)\n",
       "\n",
       "Preprocessing pipeline dedicated to work with HuggingFace datasets."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HuggingFacePreprocessingPipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ced7d",
   "metadata": {},
   "source": [
    "Then we need to use `run` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c627fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PreprocessingPipeline.run\n",
       "\n",
       ">      PreprocessingPipeline.run ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PreprocessingPipeline.run\n",
       "\n",
       ">      PreprocessingPipeline.run ()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HuggingFacePreprocessingPipeline.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4719a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: polemo2-official/all_text\n",
      "Found cached dataset polemo2-official (/root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70)\n",
      "100%|██████████| 3/3 [00:00<00:00, 686.58it/s]\n",
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-b5e701b965017bbe.arrow and /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-d36fd2c84292ba9d.arrow\n",
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-9d13530ab41d82c9.arrow and /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-74e215c973e94d28.arrow\n",
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-6346d474ca034e90.arrow and /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-41211b1e0d49b1a0.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-70edec5187afa103.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-e67460eb4958117c.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-523e94334b84a3ad.arrow\n",
      "                                                                                      \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 7\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|exec_doc\n",
    "prepocessing = HuggingFacePreprocessingPipeline(\n",
    "    dataset_name=\"clarin-pl/polemo2-official\",\n",
    "    persist_path=\"data/polemo2_downsampled\",\n",
    "    downsample_splits=(0.001, 0.005, 0.005)\n",
    ")\n",
    "prepocessing.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca9ad9",
   "metadata": {},
   "source": [
    "We have now our data prepared locally, now we need to define our `pipeline`.\n",
    "\n",
    "Let's start from config. \n",
    " We will use parameters from [`clarin-pl/lepiszcze-allegro__herbert-base-cased-polemo2`](https://huggingface.co/clarin-pl/lepiszcze-allegro__herbert-base-cased-polemo2), which configuration was obtained from `extensive hyperparmeter search`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d208178",
   "metadata": {},
   "source": [
    "::: {.callout-warning}  \n",
    "Due to hardware limitation we limit parmeter `max_epochs` to 1 and we leave `early stopping` configuration parameters as defaults \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b16164a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningBasicConfig\n",
       "\n",
       ">      LightningBasicConfig (use_scheduler:bool=True, optimizer:str='Adam',\n",
       ">                            warmup_steps:int=100, learning_rate:float=0.0001,\n",
       ">                            adam_epsilon:float=1e-08, weight_decay:float=0.0,\n",
       ">                            finetune_last_n_layers:int=-1,\n",
       ">                            classifier_dropout:Optional[float]=None,\n",
       ">                            max_seq_length:Optional[int]=None,\n",
       ">                            batch_size:int=32, max_epochs:Optional[int]=None,\n",
       ">                            early_stopping_monitor:str='val/Loss',\n",
       ">                            early_stopping_mode:str='min',\n",
       ">                            early_stopping_patience:int=3)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningBasicConfig\n",
       "\n",
       ">      LightningBasicConfig (use_scheduler:bool=True, optimizer:str='Adam',\n",
       ">                            warmup_steps:int=100, learning_rate:float=0.0001,\n",
       ">                            adam_epsilon:float=1e-08, weight_decay:float=0.0,\n",
       ">                            finetune_last_n_layers:int=-1,\n",
       ">                            classifier_dropout:Optional[float]=None,\n",
       ">                            max_seq_length:Optional[int]=None,\n",
       ">                            batch_size:int=32, max_epochs:Optional[int]=None,\n",
       ">                            early_stopping_monitor:str='val/Loss',\n",
       ">                            early_stopping_mode:str='min',\n",
       ">                            early_stopping_patience:int=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningBasicConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a1686d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningBasicConfig(use_scheduler=True, optimizer='Adam', warmup_steps=100, learning_rate=0.001, adam_epsilon=1e-06, weight_decay=0.001, finetune_last_n_layers=3, classifier_dropout=0.2, max_seq_length=None, batch_size=64, max_epochs=1, early_stopping_monitor='val/Loss', early_stopping_mode='min', early_stopping_patience=3, tokenizer_kwargs={}, batch_encoding_kwargs={}, dataloader_kwargs={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|exec_doc\n",
    "\n",
    "config = LightningBasicConfig(\n",
    "        use_scheduler=True,\n",
    "        optimizer=\"Adam\",\n",
    "        warmup_steps=100,\n",
    "        learning_rate=0.001,\n",
    "        adam_epsilon=1e-06,\n",
    "        weight_decay=0.001,\n",
    "        finetune_last_n_layers=3,\n",
    "        classifier_dropout=0.2,\n",
    "        max_seq_length=None,\n",
    "        batch_size=64,\n",
    "        max_epochs=1,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e53f5",
   "metadata": {},
   "source": [
    "Now we define pipeline dedicated for text classification `LightningClassificationPipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7297f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.pipeline.lightning_classification import LightningClassificationPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aa29a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningClassificationPipeline\n",
       "\n",
       ">      LightningClassificationPipeline\n",
       ">                                       (embedding_name_or_path:Union[str,pathli\n",
       ">                                       b.Path], dataset_name_or_path:Union[str,\n",
       ">                                       pathlib.Path], input_column_name:Union[s\n",
       ">                                       tr,Sequence[str]],\n",
       ">                                       target_column_name:str,\n",
       ">                                       output_path:Union[str,pathlib.Path], eva\n",
       ">                                       luation_filename:str='evaluation.json', \n",
       ">                                       config:Union[embeddings.config.lightning\n",
       ">                                       _config.LightningBasicConfig,embeddings.\n",
       ">                                       config.lightning_config.LightningAdvance\n",
       ">                                       dConfig]=LightningBasicConfig(use_schedu\n",
       ">                                       ler=True, optimizer='Adam',\n",
       ">                                       warmup_steps=100, learning_rate=0.0001,\n",
       ">                                       adam_epsilon=1e-08, weight_decay=0.0,\n",
       ">                                       finetune_last_n_layers=-1,\n",
       ">                                       classifier_dropout=None,\n",
       ">                                       max_seq_length=None, batch_size=32,\n",
       ">                                       max_epochs=None,\n",
       ">                                       early_stopping_monitor='val/Loss',\n",
       ">                                       early_stopping_mode='min',\n",
       ">                                       early_stopping_patience=3,\n",
       ">                                       tokenizer_kwargs={},\n",
       ">                                       batch_encoding_kwargs={},\n",
       ">                                       dataloader_kwargs={}), devices:Union[int\n",
       ">                                       ,List[int],str,NoneType]='auto', acceler\n",
       ">                                       ator:Union[str,pytorch_lightning.acceler\n",
       ">                                       ators.accelerator.Accelerator,NoneType]=\n",
       ">                                       'auto', logging_config:embeddings.utils.\n",
       ">                                       loggers.LightningLoggingConfig=Lightning\n",
       ">                                       LoggingConfig(loggers_names=[],\n",
       ">                                       tracking_project_name=None,\n",
       ">                                       wandb_entity=None,\n",
       ">                                       wandb_logger_kwargs={}), tokenizer_name_\n",
       ">                                       or_path:Union[pathlib.Path,str,NoneType]\n",
       ">                                       =None, predict_subset:embeddings.data.da\n",
       ">                                       taset.LightingDataModuleSubset=<Lighting\n",
       ">                                       DataModuleSubset.TEST: 'test'>, load_dat\n",
       ">                                       aset_kwargs:Optional[Dict[str,Any]]=None\n",
       ">                                       , model_checkpoint_kwargs:Optional[Dict[\n",
       ">                                       str,Any]]=None)\n",
       "\n",
       "Helper class that provides a standard way to create an ABC using\n",
       "inheritance."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningClassificationPipeline\n",
       "\n",
       ">      LightningClassificationPipeline\n",
       ">                                       (embedding_name_or_path:Union[str,pathli\n",
       ">                                       b.Path], dataset_name_or_path:Union[str,\n",
       ">                                       pathlib.Path], input_column_name:Union[s\n",
       ">                                       tr,Sequence[str]],\n",
       ">                                       target_column_name:str,\n",
       ">                                       output_path:Union[str,pathlib.Path], eva\n",
       ">                                       luation_filename:str='evaluation.json', \n",
       ">                                       config:Union[embeddings.config.lightning\n",
       ">                                       _config.LightningBasicConfig,embeddings.\n",
       ">                                       config.lightning_config.LightningAdvance\n",
       ">                                       dConfig]=LightningBasicConfig(use_schedu\n",
       ">                                       ler=True, optimizer='Adam',\n",
       ">                                       warmup_steps=100, learning_rate=0.0001,\n",
       ">                                       adam_epsilon=1e-08, weight_decay=0.0,\n",
       ">                                       finetune_last_n_layers=-1,\n",
       ">                                       classifier_dropout=None,\n",
       ">                                       max_seq_length=None, batch_size=32,\n",
       ">                                       max_epochs=None,\n",
       ">                                       early_stopping_monitor='val/Loss',\n",
       ">                                       early_stopping_mode='min',\n",
       ">                                       early_stopping_patience=3,\n",
       ">                                       tokenizer_kwargs={},\n",
       ">                                       batch_encoding_kwargs={},\n",
       ">                                       dataloader_kwargs={}), devices:Union[int\n",
       ">                                       ,List[int],str,NoneType]='auto', acceler\n",
       ">                                       ator:Union[str,pytorch_lightning.acceler\n",
       ">                                       ators.accelerator.Accelerator,NoneType]=\n",
       ">                                       'auto', logging_config:embeddings.utils.\n",
       ">                                       loggers.LightningLoggingConfig=Lightning\n",
       ">                                       LoggingConfig(loggers_names=[],\n",
       ">                                       tracking_project_name=None,\n",
       ">                                       wandb_entity=None,\n",
       ">                                       wandb_logger_kwargs={}), tokenizer_name_\n",
       ">                                       or_path:Union[pathlib.Path,str,NoneType]\n",
       ">                                       =None, predict_subset:embeddings.data.da\n",
       ">                                       taset.LightingDataModuleSubset=<Lighting\n",
       ">                                       DataModuleSubset.TEST: 'test'>, load_dat\n",
       ">                                       aset_kwargs:Optional[Dict[str,Any]]=None\n",
       ">                                       , model_checkpoint_kwargs:Optional[Dict[\n",
       ">                                       str,Any]]=None)\n",
       "\n",
       "Helper class that provides a standard way to create an ABC using\n",
       "inheritance."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningClassificationPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55200cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict # For metrics conversion\n",
    "import pandas as pd  # For metrics conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f1256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.46ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.29ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.20ba/s]\n",
      "Casting the dataset: 100%|██████████| 1/1 [00:00<00:00, 173.49ba/s]\n",
      "Casting the dataset: 100%|██████████| 1/1 [00:00<00:00, 169.30ba/s]\n",
      "Casting the dataset: 100%|██████████| 1/1 [00:00<00:00, 172.10ba/s]\n"
     ]
    }
   ],
   "source": [
    "#|exec_doc\n",
    "pipeline = LightningClassificationPipeline(\n",
    "    embedding_name_or_path=\"hf-internal-testing/tiny-albert\",\n",
    "    dataset_name_or_path=\"data/polemo2_downsampled/\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    "    output_path=\".\",\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"cpu\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285db21",
   "metadata": {},
   "source": [
    "Similarly as with HuggingFacePreprocessingPipeline we use `run` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0302480a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningPipeline.run\n",
       "\n",
       ">      LightningPipeline.run (run_name:Optional[str]=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningPipeline.run\n",
       "\n",
       ">      LightningPipeline.run (run_name:Optional[str]=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningClassificationPipeline.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7b0f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hf-internal-testing/tiny-albert were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at hf-internal-testing/tiny-albert and are newly initialized: ['classifier.bias', 'albert.pooler.weight', 'albert.pooler.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name          | Type                            | Params\n",
      "------------------------------------------------------------------\n",
      "0 | model         | AlbertForSequenceClassification | 352 K \n",
      "1 | metrics       | MetricCollection                | 0     \n",
      "2 | train_metrics | MetricCollection                | 0     \n",
      "3 | val_metrics   | MetricCollection                | 0     \n",
      "4 | test_metrics  | MetricCollection                | 0     \n",
      "------------------------------------------------------------------\n",
      "352 K     Trainable params\n",
      "0         Non-trainable params\n",
      "352 K     Total params\n",
      "1.410     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:00<00:00, 14.22it/s, loss=1.39, v_num=, train/BaseLR=0.000, train/LambdaLR=0.000, val/MulticlassAccuracy=0.200, val/MulticlassPrecision=0.050, val/MulticlassRecall=0.250, val/MulticlassF1Score=0.0833]\n",
      "Testing: 0it [00:00, ?it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/Loss': 1.3870834112167358,\n",
      " 'test/MulticlassAccuracy': 0.0,\n",
      " 'test/MulticlassF1Score': 0.0,\n",
      " 'test/MulticlassPrecision': 0.0,\n",
      " 'test/MulticlassRecall': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 48.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /app/nbs/01_Tutorials/checkpoints/epoch=0-step=0.ckpt\n",
      "Loaded model weights from checkpoint at /app/nbs/01_Tutorials/checkpoints/epoch=0-step=0.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#|exec_doc\n",
    "metrics = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a66101c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_macro</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_micro</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_weighted</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_macro</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_micro</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_weighted</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <td>{0: {'precision': 0.0, 'recall': 0.0, 'f1': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>{'y_pred': [0, 0, 0, 0, 0], 'y_true': [1, 1, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               values\n",
       "accuracy                                                          0.0\n",
       "f1_macro                                                          0.0\n",
       "f1_micro                                                          0.0\n",
       "f1_weighted                                                       0.0\n",
       "recall_macro                                                      0.0\n",
       "recall_micro                                                      0.0\n",
       "recall_weighted                                                   0.0\n",
       "precision_macro                                                   0.0\n",
       "precision_micro                                                   0.0\n",
       "precision_weighted                                                0.0\n",
       "classes             {0: {'precision': 0.0, 'recall': 0.0, 'f1': 0....\n",
       "data                {'y_pred': [0, 0, 0, 0, 0], 'y_true': [1, 1, 1..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame.from_dict(asdict(metrics), orient=\"index\", columns=[\"values\"])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1541a",
   "metadata": {},
   "source": [
    "## Running pipeline with AdvancedConfig\n",
    "\n",
    "As mentioned in previous section `LightningBasicConfig` is only limited to most important parameters. \n",
    "\n",
    "Let's see an example of the process of defining the parameters in our `LightningAdvancedConfig`. \n",
    "Tracing back different kwargs we can find: \n",
    "\n",
    "\n",
    "1. [`task_train_kwargs`](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-flags)\n",
    "Parameters that are passed to the `Lightning Trainer` object.\n",
    "\n",
    "\n",
    "1. [`task_model_kwargs`](https://github.com/CLARIN-PL/embeddings/blob/main/embeddings/model/lightning_module/lightning_module.py#L19)\n",
    "Parameters that are passed to the `Lightning module` object (we use `TextClassificationModule` which inherits from `HuggingFaceLightningModule` and `HuggingFaceLightningModule`).\n",
    "\n",
    "1. [`datamodule_kwargs`](https://github.com/CLARIN-PL/embeddings/blob/main/embeddings/data/datamodule.py#L35)  \n",
    "Parameters passed to the datamodule classes, currently `HuggingFaceDataModule` takes several arguments (such as max_seq_length, processing_batch_size or downsamples args) as an input\n",
    "\n",
    "1. [`batch_encoding_kwargs`](https://github.com/huggingface/transformers/blob/main/src/transformers/tokenization_utils_base.py#L2456)\n",
    "Parameters that are defined in `__call__` method of the tokenizer which allow for manipulation of the tokenized text by setting parameters such as truncation, padding, stride etc. and specifying the return format of the tokenized text\n",
    "\n",
    "1. [`tokenizer_kwargs`](https://github.com/huggingface/transformers/blob/074645e32acda6498f16203a8459bb597610f623/src/transformers/models/auto/tokenization_auto.py#L351)\n",
    "This is a generic configuration class of the hugginface model's tokenizer, possible parameters depends on the tokenizer that is used. For example for bert uncased tokenizer these parameters are present here: https://huggingface.co/bert-base-uncased/blob/main/tokenizer_config.json\n",
    "\n",
    "1. [`load_dataset_kwargs`](https://huggingface.co/docs/datasets/v2.0.0/en/package_reference/loading_methods#datasets.load_dataset)\n",
    "Keyword arguments from the `datasets.load_dataset method` which loads a dataset from the Hugging Face Hub, or a local dataset; mostly metadata for downloading, loading, caching the dataset\n",
    "\n",
    "1. [`model_config_kwargs`](https://github.com/huggingface/transformers/blob/074645e32acda6498f16203a8459bb597610f623/src/transformers/models/auto/configuration_auto.py#L515)\n",
    "This is a generic configuration class of the hugginface model, possible parameters depends on the model that is used. For example for bert uncased these parameters are present here: https://huggingface.co/bert-base-uncased/blob/main/config.json\n",
    "\n",
    "1. [`early_stopping_kwargs`](  \n",
    "https://github.com/PyTorchLightning/pytorch-lightning/blob/5d2d9b09df5359226fea6ad2722592839ac0ebc4/pytorch_lightning/callbacks/early_stopping.py#L35) \n",
    "Params defined in `__init__` of the `EarlyStopping` lightning callback; you can specify a metric to monitor and conditions to stop training when it stops improving \n",
    "1. [`dataloader_kwargs`](\n",
    "https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html#DataLoader) \n",
    "Defined in `__init__` of the torch `DataLoader` object which wraps an iterable around the Dataset to enable easy access to the sample; specify params such as num of workers, sampling or shuffling\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "524b2337",
   "metadata": {},
   "source": [
    "Lets create an advanced config with all the parameters we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e18cd711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningAdvancedConfig(finetune_last_n_layers=0, task_model_kwargs={'learning_rate': 0.001, 'train_batch_size': 64, 'eval_batch_size': 64, 'use_scheduler': True, 'optimizer': 'Adam', 'adam_epsilon': 1e-06, 'warmup_steps': 100, 'weight_decay': 0.001}, datamodule_kwargs={'max_seq_length': None}, task_train_kwargs={'max_epochs': 1, 'devices': 'auto', 'accelerator': 'cpu', 'deterministic': True}, model_config_kwargs={'classifier_dropout': 0.2}, early_stopping_kwargs=None, tokenizer_kwargs={}, batch_encoding_kwargs={}, dataloader_kwargs={})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|exec_doc\n",
    "\n",
    "advanced_config = LightningAdvancedConfig(\n",
    "    finetune_last_n_layers=0,\n",
    "    datamodule_kwargs={\n",
    "        \"max_seq_length\": None,\n",
    "    },\n",
    "    task_train_kwargs={\n",
    "        \"max_epochs\": 1,\n",
    "        \"devices\": \"auto\",\n",
    "        \"accelerator\": \"cpu\",\n",
    "        \"deterministic\": True,\n",
    "    },\n",
    "    task_model_kwargs={\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"train_batch_size\": 64,\n",
    "        \"eval_batch_size\": 64,\n",
    "        \"use_scheduler\": True,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"adam_epsilon\": 1e-6,\n",
    "        \"warmup_steps\": 100,\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    early_stopping_kwargs=None,\n",
    "    model_config_kwargs={\"classifier_dropout\": 0.2},\n",
    "    tokenizer_kwargs={},\n",
    "    batch_encoding_kwargs={},\n",
    "    dataloader_kwargs={}\n",
    ")\n",
    "advanced_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0052806",
   "metadata": {},
   "source": [
    "Now we can add config the pipeline and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d59e9ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /app/nbs/01_Tutorials/data/polemo2_downsampled/train/cache-77e994fb05243ad6.arrow\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.48ba/s]\n",
      "Loading cached processed dataset at /app/nbs/01_Tutorials/data/polemo2_downsampled/test/cache-75bdd677854c6d1d.arrow\n",
      "Loading cached processed dataset at /app/nbs/01_Tutorials/data/polemo2_downsampled/train/cache-cf1f2693fe2c5dfe.arrow\n",
      "Casting the dataset: 100%|██████████| 1/1 [00:00<00:00, 179.47ba/s]\n",
      "Loading cached processed dataset at /app/nbs/01_Tutorials/data/polemo2_downsampled/test/cache-b8547187eb8006cc.arrow\n",
      "Some weights of the model checkpoint at hf-internal-testing/tiny-albert were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at hf-internal-testing/tiny-albert and are newly initialized: ['classifier.bias', 'albert.pooler.weight', 'albert.pooler.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name          | Type                            | Params\n",
      "------------------------------------------------------------------\n",
      "0 | model         | AlbertForSequenceClassification | 352 K \n",
      "1 | metrics       | MetricCollection                | 0     \n",
      "2 | train_metrics | MetricCollection                | 0     \n",
      "3 | val_metrics   | MetricCollection                | 0     \n",
      "4 | test_metrics  | MetricCollection                | 0     \n",
      "------------------------------------------------------------------\n",
      "132       Trainable params\n",
      "352 K     Non-trainable params\n",
      "352 K     Total params\n",
      "1.410     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:00<00:00, 16.25it/s, loss=1.39, v_num=, train/BaseLR=0.000, train/LambdaLR=0.000, val/MulticlassAccuracy=0.400, val/MulticlassPrecision=0.100, val/MulticlassRecall=0.250, val/MulticlassF1Score=0.143]\n",
      "Testing: 0it [00:00, ?it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/Loss': 1.3838523626327515,\n",
      " 'test/MulticlassAccuracy': 0.6000000238418579,\n",
      " 'test/MulticlassF1Score': 0.1875,\n",
      " 'test/MulticlassPrecision': 0.15000000596046448,\n",
      " 'test/MulticlassRecall': 0.25}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 45.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /app/nbs/01_Tutorials/checkpoints/epoch=0-step=0-v1.ckpt\n",
      "Loaded model weights from checkpoint at /app/nbs/01_Tutorials/checkpoints/epoch=0-step=0-v1.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#|exec_doc\n",
    "\n",
    "pipeline = LightningClassificationPipeline(\n",
    "    embedding_name_or_path=\"hf-internal-testing/tiny-albert\",\n",
    "    dataset_name_or_path=\"data/polemo2_downsampled/\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    "    output_path=\".\",\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"cpu\",\n",
    "    config=advanced_config\n",
    ")\n",
    "\n",
    "metrics_adv_cfg = pipeline.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b35df692",
   "metadata": {},
   "source": [
    "Finally, we can check out some of the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3408fa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_macro</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_micro</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_weighted</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_macro</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_micro</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_weighted</th>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <td>{0: {'precision': 0.6, 'recall': 1.0, 'f1': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>{'y_pred': [1, 1, 1, 1, 1], 'y_true': [1, 1, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               values\n",
       "accuracy                                                          0.6\n",
       "f1_macro                                                         0.25\n",
       "f1_micro                                                          0.6\n",
       "f1_weighted                                                      0.45\n",
       "recall_macro                                                 0.333333\n",
       "recall_micro                                                      0.6\n",
       "recall_weighted                                                   0.6\n",
       "precision_macro                                                   0.2\n",
       "precision_micro                                                   0.6\n",
       "precision_weighted                                               0.36\n",
       "classes             {0: {'precision': 0.6, 'recall': 1.0, 'f1': 0....\n",
       "data                {'y_pred': [1, 1, 1, 1, 1], 'y_true': [1, 1, 1..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_adv_cfg = pd.DataFrame.from_dict(asdict(metrics_adv_cfg), orient=\"index\", columns=[\"values\"])\n",
    "metrics_adv_cfg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "727e2d65",
   "metadata": {},
   "source": [
    "We used a very small dataset and very small Language Model, so the results are not very good. However, in reality we surely will get better results with more sophisticated models and larger datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25fca9d2",
   "metadata": {},
   "source": [
    "Good luck in your experiments!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "86b40992624b6ecf125385760a49d2b554d653d5c84d942a6f4a5512888cc722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

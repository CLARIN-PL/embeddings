{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc85c5f",
   "metadata": {},
   "source": [
    "# LM-based models inference\n",
    "\n",
    "> Inference for LM-based models\n",
    "\n",
    "- title-block-banner: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ac2b5-06e8-46bc-a626-9384a35920e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019b750-cebe-438b-b1ab-434d6f756864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "from typing import Any, Dict\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from embeddings.config.lightning_config import LightningAdvancedConfig\n",
    "from embeddings.defaults import DATASET_PATH, RESULTS_PATH\n",
    "from embeddings.model.lightning_module.text_classification import (\n",
    "    TextClassificationModule,\n",
    ")\n",
    "from embeddings.pipeline.hf_preprocessing_pipeline import (\n",
    "    HuggingFacePreprocessingPipeline,\n",
    ")\n",
    "from embeddings.pipeline.lightning_classification import LightningClassificationPipeline\n",
    "from embeddings.task.lightning_task.text_classification import TextClassificationTask\n",
    "from embeddings.utils.utils import build_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e06e2-3c5a-420b-b065-31d5ccd6b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_name_or_path = \"hf-internal-testing/tiny-albert\"\n",
    "dataset_name = \"clarin-pl/polemo2-official\"\n",
    "\n",
    "dataset_path = build_output_path(DATASET_PATH, embedding_name_or_path, dataset_name)\n",
    "output_path = build_output_path(RESULTS_PATH, embedding_name_or_path, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0098c-41ec-473a-954a-709f7fb05922",
   "metadata": {},
   "source": [
    "### Preprocess and downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d1c88-900f-4275-a879-f9efdb73265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(path: str) -> Dict[str, Any]:\n",
    "    pipeline = HuggingFacePreprocessingPipeline(\n",
    "        dataset_name=dataset_name,\n",
    "        load_dataset_kwargs={\n",
    "            \"train_domains\": [\"hotels\", \"medicine\"],\n",
    "            \"dev_domains\": [\"hotels\", \"medicine\"],\n",
    "            \"test_domains\": [\"hotels\", \"medicine\"],\n",
    "            \"text_cfg\": \"text\",\n",
    "        },\n",
    "        persist_path=path,\n",
    "        sample_missing_splits=None,\n",
    "        ignore_test_subset=False,\n",
    "        downsample_splits=(0.01, 0.01, 0.05),\n",
    "        seed=441,\n",
    "    )\n",
    "    pipeline.run()\n",
    "\n",
    "    return {\n",
    "        \"dataset_name_or_path\": path,\n",
    "        \"input_column_name\": [\"text\"],\n",
    "        \"target_column_name\": \"target\",\n",
    "    }\n",
    "\n",
    "\n",
    "dataset_kwargs = preprocess_data(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159445cd-fb59-4964-aca2-ce9c18a8cf5e",
   "metadata": {},
   "source": [
    "### Train simple downsampled pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7ebd4-182c-4797-b5de-a7069313a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LightningAdvancedConfig(\n",
    "    finetune_last_n_layers=0,\n",
    "    task_train_kwargs={\"max_epochs\": 1, \"deterministic\": True,},\n",
    "    task_model_kwargs={\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"train_batch_size\": 32,\n",
    "        \"eval_batch_size\": 32,\n",
    "        \"use_scheduler\": True,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"adam_epsilon\": 1e-8,\n",
    "        \"warmup_steps\": 100,\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "    datamodule_kwargs={\"max_seq_length\": 64,},\n",
    "    early_stopping_kwargs={\"monitor\": \"val/Loss\", \"mode\": \"min\", \"patience\": 3,},\n",
    "    tokenizer_kwargs={},\n",
    "    batch_encoding_kwargs={},\n",
    "    dataloader_kwargs={},\n",
    "    model_config_kwargs={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a0089-f461-4948-93fa-04f2e34ac9e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = LightningClassificationPipeline(\n",
    "    embedding_name_or_path=embedding_name_or_path,\n",
    "    output_path=output_path,\n",
    "    config=config,\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"cpu\",\n",
    "    **dataset_kwargs\n",
    ")\n",
    "result = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491215dc-9960-4ad0-bc14-6d61d1fafac8",
   "metadata": {},
   "source": [
    "### Load model from chechpoint automatically generated with Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e824c-00f1-45b0-9e32-1bd33f364f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = output_path / \"checkpoints\" / \"last.ckpt\"\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785fcbc-1c95-4d23-807f-a14569992354",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_from_ckpt = TextClassificationTask.from_checkpoint(\n",
    "    checkpoint_path=ckpt_path, output_path=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13272a49-8ef5-41af-80a3-5cf3b7b677c7",
   "metadata": {},
   "source": [
    "#### Alternatively we can load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32fd93-e43d-4c42-961e-53232bf9e02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_from_ckpt = TextClassificationModule.load_from_checkpoint(str(ckpt_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e7972-c386-4c44-9b58-0385213f20f8",
   "metadata": {},
   "source": [
    "The warning appears when loading the model, however, it was validated that the loaded weights are the same as the weights that are being saved. The reason for this is that when the model_state_dict keys are loaded from the cached huggingface model some of them (cls.(...)) do not match the keys from the state_dict of the model weights that are saved.\n",
    "\n",
    "https://github.com/CLARIN-PL/embeddings/issues/225"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7a6c7-449f-4d0c-9042-a5f98aebc14b",
   "metadata": {},
   "source": [
    "### Use task from checkpoint for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eeab69-e13c-4ba4-b0ea-2473555915d9",
   "metadata": {},
   "source": [
    "`return_names` needs to be set to False since it uses the `datamodule` to retrieves the names while the datamodule is not loaded to `Trainer` in the `LightningTask` since we have not fitted it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7b9b0-823a-4c8e-aac5-61a333558ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = pipeline.datamodule.test_dataloader()\n",
    "preds = task_from_ckpt.predict(test_dataloader)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c789d71-2368-4add-8a7b-f51571aecfbd",
   "metadata": {},
   "source": [
    "Alternatively we can implicitly assign the `datamodule` to `Trainer` in `LightningTask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836dc5d-8ee2-46fc-b7d8-94841cc13ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_from_ckpt.trainer.datamodule = pipeline.datamodule\n",
    "preds_with_names = task_from_ckpt.predict(test_dataloader, return_names=True)\n",
    "preds_with_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c321e2-9ecc-4b65-936b-c8e7cca1155a",
   "metadata": {},
   "source": [
    "We can also use previosly loaded lightning model (`LightningModule`) outside of the task and get the predictions. To do this we also need to intitialize a `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afa250-2937-4aad-bb3c-172a68639892",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(default_root_dir=str(output_path))\n",
    "preds_from_model = trainer.predict(model_from_ckpt, dataloaders=test_dataloader)\n",
    "preds_from_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('embeddings')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "86b40992624b6ecf125385760a49d2b554d653d5c84d942a6f4a5512888cc722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEPISZCZE\n",
    "\n",
    "> The use cases and examples how to train and submit models to the [LEPISZCZE](https://lepiszcze.ml/). \n",
    "\n",
    "- bibliography: ../references.bib\n",
    "- title-block-banner: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp lepiszcze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_854/865539875.py:3: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML, display\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { max-width:1800px !important;width:auto; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "display(HTML(\"<style>.container { max-width:1800px !important;width:auto; }</style>\"))\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We recommend to read our NeurIPS paper [@augustyniak2022this] where you can find our lessons learned from the process of designing and compiling LEPISZCZE benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from embeddings.config.lightning_config import LightningBasicConfig, LightningAdvancedConfig\n",
    "from embeddings.pipeline.lightning_classification import LightningClassificationPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with training a text classifier using `embeddings.pipeline.lightning_classification.LightningClassificationPipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr/>\n",
       "<h3>LightningClassificationPipeline</h3>\n",
       "<blockquote><pre><code>LightningClassificationPipeline(embedding_name_or_path:Union[str,pathlib.Path], dataset_name_or_path:Union[str,pathlib.Path], input_column_name:Union[str,Sequence[str]], target_column_name:str, output_path:Union[str,pathlib.Path], evaluation_filename:str='evaluation.json', config:Union[embeddings.config.lightning_config.LightningBasicConfig,embeddings.config.lightning_config.LightningAdvancedConfig]=LightningBasicConfig(use_scheduler=True, optimizer='Adam', warmup_steps=100, learning_rate=0.0001, adam_epsilon=1e-08, weight_decay=0.0, finetune_last_n_layers=-1, classifier_dropout=None, max_seq_length=None, batch_size=32, max_epochs=None, early_stopping_monitor='val/Loss', early_stopping_mode='min', early_stopping_patience=3, tokenizer_kwargs={}, batch_encoding_kwargs={}, dataloader_kwargs={}), devices:Union[List[int],str,int,NoneType]='auto', accelerator:Union[str,pytorch_lightning.accelerators.accelerator.Accelerator,NoneType]='auto', logging_config:embeddings.utils.loggers.LightningLoggingConfig=LightningLoggingConfig(loggers_names=[], tracking_project_name=None, wandb_entity=None, wandb_logger_kwargs={}), tokenizer_name_or_path:Union[str,pathlib.Path,NoneType]=None, predict_subset:embeddings.data.dataset.LightingDataModuleSubset=<LightingDataModuleSubset.TEST: 'test'>, load_dataset_kwargs:Optional[Dict[str,Any]]=None, model_checkpoint_kwargs:Optional[Dict[str,Any]]=None)</code></pre></blockquote><p>Helper class that provides a standard way to create an ABC using\n",
       "inheritance.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(LightningClassificationPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEPISZCZE_SUBMISSIONS = Path(\"../lepiszcze-submissions\")\n",
    "LEPISZCZE_SUBMISSIONS.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LightningBasicConfig(\n",
    "    learning_rate=0.01, max_epochs=1, max_seq_length=128, finetune_last_n_layers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: polemo2-official/all_text\n",
      "Found cached dataset polemo2-official (/root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70)\n",
      "100%|██████████| 3/3 [00:00<00:00, 277.11it/s]\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-f315ad251f6218f5.arrow\n",
      "  0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-a652821a41c5b53a.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-2614cc27a4c1f826.arrow\n",
      "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-adffd369ddd3fae9.arrow\n"
     ]
    }
   ],
   "source": [
    "pipeline = LightningClassificationPipeline(\n",
    "    dataset_name_or_path=\"clarin-pl/polemo2-official\",\n",
    "    embedding_name_or_path=\"distilbert-base-uncased\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    "    output_path=\".\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took a couple of seconds but finally we have a pipeline objects ready and we need only run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.config.lightning_config import LightningAdvancedConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: polemo2-official/all_text\n",
      "Found cached dataset polemo2-official (/root/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70)\n",
      "100%|██████████| 3/3 [00:00<00:00, 254.26it/s]\n",
      "/opt/conda/envs/embeddings/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:849: UserWarning: You requested multiple GPUs but did not specify a backend, e.g. `Trainer(strategy=\"dp\"|\"ddp\"|\"ddp2\")`. Setting `strategy=\"ddp_spawn\"` for you.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = pipeline.run()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "import typer\n",
    "\n",
    "from embeddings.defaults import RESULTS_PATH\n",
    "from embeddings.pipeline.flair_classification import FlairClassificationPipeline\n",
    "from embeddings.utils.utils import build_output_path, format_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \".\"\n",
    "embedding_name_or_path = \"clarin-pl/word2vec-kgr10\"\n",
    "dataset_name = \"clarin-pl/polemo2-official\"\n",
    "input_column_name = \"text\"\n",
    "target_column_name = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 22:35:55,493 - embeddings.utils.utils - WARNING - String 'clarin-pl/word2vec-kgr10' contains '/'. Replacing it with '__'. Cleaned_text: clarin-pl__word2vec-kgr10.\n",
      "2022-11-13 22:35:55,496 - embeddings.utils.utils - WARNING - String 'clarin-pl/polemo2-official' contains '/'. Replacing it with '__'. Cleaned_text: clarin-pl__polemo2-official.\n",
      "2022-11-13 22:35:56,661 - embeddings.embedding.auto_flair - INFO - clarin-pl/word2vec-kgr10 not compatible with Transformers, trying to initialise as static embedding.\n",
      "/opt/conda/envs/embeddings/lib/python3.9/site-packages/huggingface_hub/file_download.py:588: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n",
      "Downloading: 100%|██████████| 76.0/76.0 [00:00<00:00, 39.7kB/s]\n",
      "Downloading: 100%|██████████| 72.0/72.0 [00:00<00:00, 42.1kB/s]\n",
      "Downloading: 100%|██████████| 139M/139M [01:01<00:00, 2.27MB/s] \n",
      "Downloading: 100%|██████████| 2.74G/2.74G [20:30<00:00, 2.23MB/s] \n"
     ]
    }
   ],
   "source": [
    "output_path = build_output_path(root, embedding_name_or_path, dataset_name)\n",
    "pipeline = FlairClassificationPipeline(\n",
    "    embedding_name=embedding_name_or_path,\n",
    "    dataset_name=dataset_name,\n",
    "    input_column_name=input_column_name,\n",
    "    target_column_name=target_column_name,\n",
    "    output_path=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('embeddings')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "86b40992624b6ecf125385760a49d2b554d653d5c84d942a6f4a5512888cc722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLARIN Embeddings \n",
    "\n",
    "> State-of-the-art Text Representations for Natural Language Processing tasks, an initial version of library focus on the Polish Language\n",
    "\n",
    "- bibliography: references.bib\n",
    "- title-block-banner: true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-warning}\n",
    "The library is currently in an active development state. Some functionalities may be\n",
    "subject to change before the stable release. Users can track our\n",
    "milestones [here](https://github.com/CLARIN-PL/embeddings/milestones).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Installation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "pip install clarinpl-embeddings\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Text-classification with polemo2 dataset and transformer-based embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from embeddings.pipeline.lightning_classification import LightningClassificationPipeline\n",
    "\n",
    "pipeline = LightningClassificationPipeline(\n",
    "    dataset_name_or_path=\"clarin-pl/polemo2-official\",\n",
    "    embedding_name_or_path=\"allegro/herbert-base-cased\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    "    output_path=\".\"\n",
    ")\n",
    "\n",
    "print(pipeline.run())\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### :warning: As for now, default pipeline model hyperparameters may provide poor results. It will be subject to change in further releases. We encourage users to use [Optimized Pipelines](#optimized-pipelines) to select appropriate hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Conventions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We use many of the HuggingFace concepts such as models (https://huggingface.co/models) or\n",
    "datasets (https://huggingface.co/datasets) to make our library as easy to use as it is possible. We\n",
    "want to enable users to create, customise, test, and execute NLP / NLU / SLU tasks in the fastest\n",
    "possible manner. Moreover, we present easy to use static embeddings, that were trained by CLARIN-PL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We share predefined pipelines for common NLP tasks with corresponding scripts. For Transformer based\n",
    "pipelines we utilize [PyTorch Lighting](https://www.pytorchlightning.ai) âš¡ trainers with\n",
    "Transformers [AutoModels](https://huggingface.co/docs/transformers/master/en/model_doc/auto#transformers.AutoModel)\n",
    ". For static embedding based pipelines we use [Flair](https://github.com/flairNLP/flair) library\n",
    "under the hood.\n",
    "\n",
    "**REMARK**: As currently we haven't blocked transformers based pipelines from **flair** pipelines\n",
    "we **may remove it in the nearest future.** We encourage to use **Lightning** based pipelines for\n",
    "transformers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Transformer embedding based pipelines (e.g. Bert, RoBERTA, Herbert):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Task                | Class                                                                                   | Script                                                                                                  | \n",
    "|---------------------|-----------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| Text classification | [LightningClassificationPipeline](embeddings/pipeline/lightning_classification.py)      | [evaluate_lightning_document_classification.py](examples/evaluate_lightning_document_classification.py) |\n",
    "| Sequence labelling  | [LightningSequenceLabelingPipeline](embeddings/pipeline/lightning_sequence_labeling.py) | [evaluate_lightning_sequence_labeling.py](examples/evaluate_lightning_sequence_labeling.py)             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Static embedding based pipelines (e.g. word2vec, fasttext)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Task                         | Class                                                                               | Script                                                                                        |\n",
    "|------------------------------|-------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|\n",
    "| Text classification          | [FlairClassificationPipeline](embeddings/pipeline/flair_classification.py)          | [evaluate_document_classification.py](examples/evaluate_document_classification.py)           |\n",
    "| Sequence labelling           | [FlairSequenceLabelingPipeline](embeddings/pipeline/flair_sequence_labeling.py)     | [evaluate_sequence_labelling.py](examples/evaluate_sequence_labelling.py)                     |\n",
    "| Sequence pair classification | [FlairPairClassificationPipeline](embeddings/pipeline/flair_pair_classification.py) | [evaluate_document_pair_classification.py](examples/evaluate_document_pair_classification.py) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Writing custom HuggingFace-based pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "from embeddings.data.data_loader import HuggingFaceDataLoader\n",
    "from embeddings.data.dataset import Dataset\n",
    "from embeddings.embedding.auto_flair import AutoFlairDocumentEmbedding\n",
    "from embeddings.evaluator.text_classification_evaluator import TextClassificationEvaluator\n",
    "from embeddings.model.flair_model import FlairModel\n",
    "from embeddings.pipeline.standard_pipeline import StandardPipeline\n",
    "from embeddings.task.flair_task.text_classification import TextClassification\n",
    "from embeddings.transformation.flair_transformation.classification_corpus_transformation import (\n",
    "    ClassificationCorpusTransformation,\n",
    ")\n",
    "\n",
    "dataset = Dataset(\"clarin-pl/polemo2-official\")\n",
    "data_loader = HuggingFaceDataLoader()\n",
    "transformation = ClassificationCorpusTransformation(\"text\", \"target\")\n",
    "embedding = AutoFlairDocumentEmbedding.from_hub(\"clarin-pl/word2vec-kgr10\")\n",
    "task = TextClassification(Path(\".\"))\n",
    "model = FlairModel(embedding, task)\n",
    "evaluator = TextClassificationEvaluator()\n",
    "\n",
    "pipeline = StandardPipeline(dataset, data_loader, transformation, model, evaluator)\n",
    "result = pipeline.run()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Running tasks scripts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "All up-to-date examples can be found under [examples](examples/) path.\n",
    "\n",
    "```bash\n",
    "cd examples\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run classification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The example with non-default arguments\n",
    "\n",
    "```bash\n",
    "python evaluate_lightning_document_classification.py \\\n",
    "    --embedding-name-or-path allegro/herbert-base-cased \\\n",
    "    --dataset-name clarin-pl/polemo2-official \\\n",
    "    --input-columns-name text \\\n",
    "    --target-column-name target\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run sequence labeling task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The example with default language model and dataset.\n",
    "\n",
    "```bash\n",
    "python evaluate_lightning_sequence_labeling.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run pair classification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The example with static embedding model.\n",
    "\n",
    "```bash\n",
    "python evaluate_document_pair_classification.py \\\n",
    "    --embedding-name-or-path clarin-pl/word2vec-kgr10\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Compatible datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As most datasets in HuggingFace repository should be compatible with our pipelines, there are\n",
    "several datasets that were tested by the authors.\n",
    "\n",
    "| dataset name                                                                                  | task type                                          | input_column_name(s)         | target_column_name  | description                                                                                                                                                                               |\n",
    "|-----------------------------------------------------------------------------------------------|--------------------------------------------------|------------------------------|---------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| [clarin-pl/kpwr-ner](https://huggingface.co/datasets/clarin-pl/kpwr-ner)                      | sequence labeling (named entity recognition)       | tokens                       | ner                 | KPWR-NER is a part of the  Polish Corpus of WrocÅ‚aw University of Technology (KPWr). Its objective is recognition of named entities, e.g., people, institutions etc.                      |\n",
    "| [clarin-pl/polemo2-official](https://huggingface.co/datasets/clarin-pl/polemo2-official )       | classification  (sentiment analysis)             | text                         | target              | A corpus of consumer reviews from 4 domains: medicine, hotels, products and school.                                                                                                       |\n",
    "| [clarin-pl/2021-punctuation-restoration](https://huggingface.co/datasets/clarin-pl/2021-punctuation-restoration)                      | punctuation restoration                           | text_in                      | text_out            | Dataset contains original texts and ASR output. It is a part of PolEval 2021 Competition.                                                                                                 |\n",
    "| [clarin-pl/nkjp-pos](https://huggingface.co/datasets/clarin-pl/nkjp-pos)                      | sequence labeling (part-of-speech tagging)       | tokens                       | pos_tags            | NKJP-POS is a part of the National Corpus of Polish. Its objective is part-of-speech tagging, e.g., nouns, verbs, adjectives, adverbs, etc.                                               |\n",
    "| [clarin-pl/aspectemo](https://huggingface.co/datasets/clarin-pl/aspectemo)                      | sequence labeling (sentiment classification)     | tokens                       | labels              | AspectEmo Corpus is an extended version of a publicly available PolEmo 2.0 corpus of Polish customer reviews used in many projects on the use of different methods in sentiment analysis. |\n",
    "| [laugustyniak/political-advertising-pl](https://huggingface.co/datasets/laugustyniak/political-advertising-pl)                      | sequence labeling (political advertising )                         | tokens                       | tags                | First publicly open dataset for detecting specific text chunks and categories of political advertising in the Polish language.                                                            |\n",
    "| [laugustyniak/abusive-clauses-pl](https://huggingface.co/datasets/laugustyniak/abusive-clauses-pl)                      | classification  (abusive-clauses)                           | text                          | class               | Dataset with Polish abusive clauses examples.                                                                                                                                             |\n",
    "| [allegro/klej-dyk](https://huggingface.co/datasets/allegro/klej-dyk)                             | pair classification (question answering)*        | (question, answer)           | target              | The Did You Know (pol. Czy wiesz?) dataset consists of human-annotated question-answer pairs.                                                                                             |\n",
    "| [allegro/klej-psc](https://huggingface.co/datasets/allegro/klej-psc)                             | pair classification (text summarization)*        | (extract_text, summary_text) | label               | The Polish Summaries Corpus contains news articles and their summaries.                                                                                                                   |\n",
    "| [allegro/klej-cdsc-e](https://huggingface.co/datasets/allegro/klej-cdsc-e)                    | pair classification (textual entailment)*        | (sentence_A, sentence_B)     | entailment_judgment | The polish sentence pairs which are human-annotated for textualentailment.                                                                                                                |\n",
    "\n",
    "<br />\n",
    "\n",
    "[//]: # ()\n",
    "<sup>*only pair classification task is supported for now</sup>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Passing task model and task training parameters to predefined flair pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model and training parameters can be controlled via `task_model_kwargs` and\n",
    "`task_train_kwargs` parameters that can be populated using the advanced config. Tutorial on how to\n",
    "use configs can be found in `/tutorials` directory of the repository. Two types of config are\n",
    "defined in our library: BasicConfig and AdvancedConfig. In summary, the BasicConfig takes arguments\n",
    "and automatically assign them into proper keyword group, while the AdvancedConfig takes as the input\n",
    "keyword groups that should be already correctly mapped.\n",
    "\n",
    "The list of available config can be found below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Flair**:\n",
    "\n",
    "- FlairBasicConfig\n",
    "- FlairSequenceLabelingBasicConfig\n",
    "- FlairTextClassificationBasicConfig\n",
    "- FlairSequenceLabelingAdvancedConfig\n",
    "- FlairTextClassificationAdvancedConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Lightning**:\n",
    "\n",
    "- LightningBasicConfig\n",
    "- LightningAdvancedConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Example with `polemo2` dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Flair pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from embeddings.pipeline.flair_classification import FlairClassificationPipeline\n",
    "from embeddings.config.flair_config import FlairTextClassificationAdvancedConfig\n",
    "\n",
    "config = FlairTextClassificationAdvancedConfig(\n",
    "    task_model_kwargs={\n",
    "        \"loss_weights\": {\n",
    "            \"plus\": 2.0,\n",
    "            \"minus\": 2.0\n",
    "        }\n",
    "    },\n",
    "    task_train_kwargs={\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"max_epochs\": 20\n",
    "    }\n",
    ")\n",
    "pipeline = FlairClassificationPipeline(\n",
    "    dataset_name=\"clarin-pl/polemo2-official\",\n",
    "    embedding_name=\"clarin-pl/word2vec-kgr10\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    "    output_path=\".\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(pipeline.run())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Lightning pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from embeddings.config.lightning_config import LightningBasicConfig\n",
    "from embeddings.pipeline.lightning_classification import LightningClassificationPipeline\n",
    "\n",
    "config = LightningBasicConfig(\n",
    "    learning_rate=0.01, max_epochs=1, max_seq_length=128, finetune_last_n_layers=0,\n",
    "    accelerator=\"cpu\"\n",
    ")\n",
    "\n",
    "pipeline = LightningClassificationPipeline(\n",
    "    embedding_name_or_path=\"allegro/herbert-base-cased\",\n",
    "    dataset_name_or_path=\"clarin-pl/polemo2-official\",\n",
    "    input_column_name=[\"text\"],\n",
    "    target_column_name=\"target\",\n",
    "    load_dataset_kwargs={\n",
    "        \"train_domains\": [\"hotels\", \"medicine\"],\n",
    "        \"dev_domains\": [\"hotels\", \"medicine\"],\n",
    "        \"test_domains\": [\"hotels\", \"medicine\"],\n",
    "        \"text_cfg\": \"text\",\n",
    "    },\n",
    "    output_path=\".\",\n",
    "    config=config\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can also define an Advanced config with populated keyword arguments. In general, the keywords\n",
    "are passed to the object when constructing specific pipelines. We can identify and trace the keyword\n",
    "arguments to find the possible arguments that can be set in the config kwargs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from embeddings.config.lightning_config import LightningAdvancedConfig\n",
    "\n",
    "config = LightningAdvancedConfig(\n",
    "    finetune_last_n_layers=0,\n",
    "    task_train_kwargs={\n",
    "        \"max_epochs\": 1,\n",
    "        \"devices\": \"auto\",\n",
    "        \"accelerator\": \"cpu\",\n",
    "        \"deterministic\": True,\n",
    "    },\n",
    "    task_model_kwargs={\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"use_scheduler\": False,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"adam_epsilon\": 1e-8,\n",
    "        \"warmup_steps\": 100,\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "    datamodule_kwargs={\n",
    "        \"downsample_train\": 0.01,\n",
    "        \"downsample_val\": 0.01,\n",
    "        \"downsample_test\": 0.05,\n",
    "    },\n",
    "    dataloader_kwargs={\"num_workers\": 0},\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Static embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Computed vectors are stored in [Flair](https://github.com/flairNLP/flair) structures\n",
    "\n",
    "- [Sentences](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_1_BASICS.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Document embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from flair.data import Sentence\n",
    "\n",
    "from embeddings.embedding.auto_flair import AutoFlairDocumentEmbedding\n",
    "\n",
    "sentence = Sentence(\"MyÅ›l z duszy leci bystro, Nim siÄ™ w sÅ‚owach zÅ‚amie.\")\n",
    "\n",
    "embedding = AutoFlairDocumentEmbedding.from_hub(\"clarin-pl/word2vec-kgr10\")\n",
    "embedding.embed([sentence])\n",
    "\n",
    "print(sentence.embedding)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Word embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from flair.data import Sentence\n",
    "\n",
    "from embeddings.embedding.auto_flair import AutoFlairWordEmbedding\n",
    "\n",
    "sentence = Sentence(\"MyÅ›l z duszy leci bystro, Nim siÄ™ w sÅ‚owach zÅ‚amie.\")\n",
    "\n",
    "embedding = AutoFlairWordEmbedding.from_hub(\"clarin-pl/word2vec-kgr10\")\n",
    "embedding.embed([sentence])\n",
    "\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Available embedding models for Polish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Instead of the `allegro/herbert-base-cased` model, user can pass any model\n",
    "from [HuggingFace Hub](https://huggingface.co/models) that is compatible\n",
    "with [Transformers](https://huggingface.co/transformers/) or with our library.\n",
    "\n",
    "| Embedding                                                                   | Type         | Description                                                      |\n",
    "|-----------------------------------------------------------------------------|--------------|------------------------------------------------------------------|\n",
    "| [clarin-pl/herbert-kgr10](https://huggingface.co/clarin-pl/herbert-kgr10)   | bert         | HerBERT Large  trained on supplementary data - the KGR10 corpus. |\n",
    "| [clarin-pl/fastText-kgr10](https://huggingface.co/clarin-pl/fastText-kgr10) | static, word | FastText trained on trained on the KGR10 corpus.                 |\n",
    "| [clarin-pl/word2vec-kgr10](https://huggingface.co/clarin-pl/word2vec-kgr10) | static, word | Word2vec trained on trained on the KGR10 corpus.                 |\n",
    "| ...                                                                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Optimized pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Transformers embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Task                          | Optimized Pipeline                                                                         |\n",
    "|-------------------------------|--------------------------------------------------------------------------------------------|\n",
    "| Lightning Text Classification | [OptimizedLightingClassificationPipeline](embeddings/pipeline/lightning_hps_pipeline.py)   | \n",
    "| Lightning Sequence Labeling   | [OptimizedLightingSequenceLabelingPipeline](embeddings/pipeline/lightning_hps_pipeline.py) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Static embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Task                           | Optimized Pipeline                                                                    |\n",
    "|--------------------------------|---------------------------------------------------------------------------------------|\n",
    "| Flair Text Classification      | [OptimizedFlairClassificationPipeline](embeddings/pipeline/flair_hps_pipeline.py)     | \n",
    "| Flair Pair Text Classification | [OptimizedFlairPairClassificationPipeline](embeddings/pipeline/flair_hps_pipeline.py) |\n",
    "| Flair Sequence Labeling        | [OptimizedFlairSequenceLabelingPipeline](embeddings/pipeline/flair_hps_pipeline.py)   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Example with Text Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Optimized pipelines can be run via following snippet of code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "\n",
    "from embeddings.config.lighting_config_space import LightingTextClassificationConfigSpace\n",
    "from embeddings.pipeline.lightning_hps_pipeline import OptimizedLightingClassificationPipeline\n",
    "\n",
    "pipeline = OptimizedLightingClassificationPipeline(\n",
    "    config_space=LightingTextClassificationConfigSpace(\n",
    "        embedding_name_or_path=\"allegro/herbert-base-cased\"\n",
    "    ),\n",
    "    dataset_name_or_path=\"clarin-pl/polemo2-official\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    ").persisting(best_params_path=\"best_prams.yaml\", log_path=\"hps_log.pickle\")\n",
    "df, metadata = pipeline.run()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training model with obtained parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After the parameters search process we can train model with best parameters found. But firstly we\n",
    "have to set `output_path` parameter, which is not automatically generated\n",
    "from `OptimizedLightingClassificationPipeline`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "metadata[\"output_path\"] = \".\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we are able to train the pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from embeddings.pipeline.lightning_classification import LightningClassificationPipeline\n",
    "\n",
    "pipeline = LightningClassificationPipeline(**metadata)\n",
    "results = pipeline.run()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Selection of best embedding model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Instead of performing search with single embedding model we can search with multiple embedding\n",
    "models via passing them as list to ConfigSpace.\n",
    "\n",
    "```python\n",
    "pipeline = OptimizedLightingClassificationPipeline(\n",
    "    config_space=LightingTextClassificationConfigSpace(\n",
    "        embedding_name_or_path=[\"allegro/herbert-base-cased\", \"clarin-pl/roberta-polish-kgr10\"]\n",
    "    ),\n",
    "    dataset_name_or_path=\"clarin-pl/polemo2-official\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    ").persisting(best_params_path=\"best_prams.yaml\", log_path=\"hps_log.pickle\")\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('embeddings')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86b40992624b6ecf125385760a49d2b554d653d5c84d942a6f4a5512888cc722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

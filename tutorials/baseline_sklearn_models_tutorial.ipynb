{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook's purpose is to show how to use the sklearn-like models pipeline for text classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline trains a selected classifier on a selected dataset, training a specified vectorizer previously. Then, it computes the text classification evaluation metrics and saves them in a JSON file in a specified path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the \"SklearnClassificationPipeline\" class, all you need to import is a selected sklearn-like classifier and any sklearn vectorizer, like CountVectorizer or TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from embeddings.pipeline.sklearn_classification import SklearnClassificationPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables you need to pass to the SklearnClassificationPipeline class:\n",
    "- __dataset kwargs__: name of the dataset and names of X and Y columns, respectively. You can pass them to the class from a dict, like in all examples below, or directly.\n",
    "- __output_path__: a path where you want a file with evaluation metrics saved.\n",
    "\n",
    "The remaining elements are optional. Note that arguments __\"embeddings_kwargs\"__ and __\"classifier_kwargs\"__ are passed to the class __without \"**\"__.\n",
    "In this notebook we are using the POLEMO2 dataset - the details about it can be found [here](https://huggingface.co/datasets/clarin-pl/polemo2-official)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_kwargs = {\n",
    "    \"max_features\": 10000,\n",
    "    \"max_df\": 10\n",
    "}\n",
    "\n",
    "classifier_kwargs = {\n",
    "    \"n_estimators\": 100\n",
    "}\n",
    "\n",
    "evaluation_filename = \"adaboost_tfidf_evaluation.json\"  #default name: evaluation_filename.json\n",
    "output_path = \".\"\n",
    "\n",
    "adaboost_tfidf_pipeline = SklearnClassificationPipeline(\n",
    "    dataset_name=\"clarin-pl/polemo2-official\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    "    output_path=output_path,\n",
    "    classifier=AdaBoostClassifier,\n",
    "    vectorizer=TfidfVectorizer,\n",
    "    evaluation_filename=evaluation_filename,\n",
    "    classifier_kwargs=classifier_kwargs,\n",
    "    embedding_kwargs=embeddings_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: pol_emo2/all_text\n",
      "Reusing dataset pol_emo2 (/Users/mariuszkossakowski/.cache/huggingface/datasets/clarin-pl___pol_emo2/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc56916a82174d328c01fcf05b16f177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassificationEvaluationResults(accuracy=0.4585365853658537, f1_macro=0.27053544591867407, f1_micro=0.4585365853658537, f1_weighted=0.3190341090580814, recall_macro=0.3325333733313334, recall_micro=0.4585365853658537, recall_weighted=0.4585365853658537, precision_macro=0.3090909090909091, precision_micro=0.4585365853658537, precision_weighted=0.2955210643015521, classes={0: {'precision': 0.8, 'recall': 0.3389830508474576, 'f1': 0.47619047619047616, 'support': 118}, 1: {'precision': 0.43636363636363634, 'recall': 0.9911504424778761, 'f1': 0.60595130748422, 'support': 339}, 2: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'support': 227}, 3: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'support': 136}}, data=Predictions(y_pred=array([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1]), y_true=array([1, 2, 2, 2, 2, 0, 0, 0, 1, 3, 1, 0, 2, 2, 2, 1, 1, 1, 1, 3, 3, 2,\n",
      "       2, 3, 1, 2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 3, 2, 1, 1, 2, 2, 1, 1, 2,\n",
      "       0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1, 0, 3, 3, 1, 0, 3,\n",
      "       0, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 3, 3,\n",
      "       2, 3, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 1, 0, 1, 1, 2, 3, 3, 2, 2, 3,\n",
      "       1, 1, 1, 3, 1, 0, 2, 1, 0, 3, 0, 3, 3, 1, 2, 1, 1, 1, 2, 0, 2, 2,\n",
      "       1, 1, 0, 2, 1, 3, 3, 0, 2, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 2, 2, 2, 1, 0, 3, 1, 1, 1, 2, 3, 0, 1, 2, 1, 1, 1, 0, 1, 1,\n",
      "       3, 0, 1, 3, 1, 1, 0, 2, 2, 2, 1, 1, 2, 3, 1, 2, 2, 2, 1, 1, 2, 1,\n",
      "       0, 3, 2, 3, 1, 0, 2, 1, 2, 3, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1,\n",
      "       1, 1, 3, 1, 1, 2, 2, 1, 1, 2, 2, 3, 2, 3, 1, 3, 1, 3, 1, 3, 2, 3,\n",
      "       2, 2, 2, 3, 1, 1, 1, 1, 2, 2, 2, 3, 1, 2, 1, 0, 2, 2, 2, 0, 1, 1,\n",
      "       1, 3, 0, 1, 3, 2, 3, 1, 0, 1, 3, 3, 2, 3, 1, 1, 1, 2, 1, 2, 0, 1,\n",
      "       0, 3, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1, 1, 3,\n",
      "       3, 2, 3, 0, 3, 0, 1, 0, 3, 0, 3, 0, 1, 1, 1, 3, 1, 3, 1, 3, 0, 0,\n",
      "       1, 1, 3, 0, 2, 0, 1, 2, 2, 0, 1, 1, 3, 2, 1, 2, 3, 3, 2, 3, 2, 2,\n",
      "       1, 0, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 1, 1, 3, 2, 1, 3, 2, 0, 1,\n",
      "       2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 1, 2, 2, 2, 0, 3, 1, 1, 0, 1, 1, 0,\n",
      "       2, 3, 0, 0, 0, 2, 3, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1,\n",
      "       2, 1, 2, 1, 3, 3, 2, 1, 1, 1, 0, 3, 3, 0, 1, 1, 3, 2, 1, 2, 3, 0,\n",
      "       2, 0, 1, 3, 1, 1, 2, 2, 2, 1, 1, 3, 1, 3, 1, 1, 0, 1, 1, 2, 1, 2,\n",
      "       1, 2, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 1, 3, 1, 1, 2, 2, 2, 1, 3, 1,\n",
      "       1, 3, 0, 2, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 3, 1,\n",
      "       0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 3, 1, 2, 1,\n",
      "       3, 2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 3, 0, 3, 2, 2, 2, 3, 2, 0, 3,\n",
      "       1, 2, 1, 0, 2, 3, 1, 1, 0, 1, 3, 1, 0, 1, 2, 3, 1, 1, 3, 3, 1, 1,\n",
      "       0, 1, 0, 3, 1, 3, 1, 0, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1,\n",
      "       2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 3, 2, 0, 3, 2, 2, 1, 3, 2,\n",
      "       2, 1, 1, 3, 2, 2, 3, 2, 1, 1, 3, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1,\n",
      "       1, 2, 1, 2, 3, 3, 3, 2, 2, 3, 2, 1, 1, 0, 1, 1, 1, 2, 2, 3, 2, 1,\n",
      "       1, 0, 2, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 2, 3, 1,\n",
      "       2, 3, 1, 1, 1, 2, 1, 2, 0, 1, 0, 3, 2, 3, 2, 1, 1, 3, 1, 1, 0, 1,\n",
      "       2, 3, 1, 3, 1, 1, 3, 1, 1, 3, 0, 0, 3, 2, 3, 1, 2, 1, 0, 2, 0, 2,\n",
      "       1, 1, 3, 1, 2, 3, 0, 1, 1, 3, 1, 0, 3, 2, 1, 1, 3, 2, 2, 1, 1, 1,\n",
      "       1, 3, 1, 0, 2, 0, 0, 1, 3, 3, 1, 3, 0, 1, 1, 0, 2, 0, 3, 1, 1, 2,\n",
      "       1, 2, 1, 1, 3, 1, 3, 3, 1, 1, 1, 1, 0, 1, 2, 2, 2, 1, 2, 0, 2, 2,\n",
      "       2, 1, 1, 2, 1, 2, 2, 1, 3, 0, 0, 3, 1, 1, 2, 1, 3, 0, 0, 2, 3, 2,\n",
      "       2, 0, 1, 3, 2, 2]), y_probabilities=None, names=None))\n"
     ]
    }
   ],
   "source": [
    "adaboost_tfidf_result = adaboost_tfidf_pipeline.run()\n",
    "print(adaboost_tfidf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svm_kwargs = {\n",
    "    \"kernel\": \"linear\",\n",
    "    \"C\": 0.6\n",
    "}\n",
    "\n",
    "evaluation_filename_svm_tdidf = \"svm_tfidf_evaluation.json\"\n",
    "\n",
    "svm_tfidf_pipeline = SklearnClassificationPipeline(\n",
    "    dataset_name=\"clarin-pl/polemo2-official\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    "    output_path=output_path,\n",
    "    classifier=SVC,\n",
    "    vectorizer=TfidfVectorizer,\n",
    "    evaluation_filename=evaluation_filename_svm_tdidf,\n",
    "    classifier_kwargs=svm_kwargs,\n",
    "    embedding_kwargs=embeddings_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: pol_emo2/all_text\n",
      "Reusing dataset pol_emo2 (/Users/mariuszkossakowski/.cache/huggingface/datasets/clarin-pl___pol_emo2/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ba1877b204b4af998d139510338c930"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassificationEvaluationResults(accuracy=0.6292682926829268, f1_macro=0.538089503921292, f1_micro=0.6292682926829268, f1_weighted=0.5821659059932924, recall_macro=0.5331545169631904, recall_micro=0.6292682926829268, recall_weighted=0.6292682926829268, precision_macro=0.6747768805779856, precision_micro=0.6292682926829268, precision_weighted=0.6410225313472854, classes={0: {'precision': 1.0, 'recall': 0.6101694915254238, 'f1': 0.7578947368421053, 'support': 118}, 1: {'precision': 0.570902394106814, 'recall': 0.9144542772861357, 'f1': 0.7029478458049886, 'support': 339}, 2: {'precision': 0.6666666666666666, 'recall': 0.5638766519823789, 'f1': 0.6109785202863962, 'support': 227}, 3: {'precision': 0.46153846153846156, 'recall': 0.04411764705882353, 'f1': 0.08053691275167787, 'support': 136}}, data=Predictions(y_pred=array([1, 2, 2, 2, 3, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
      "       2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2,\n",
      "       1, 1, 1, 0, 1, 1, 2, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 1, 2, 1, 0, 1,\n",
      "       1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1, 1, 1, 2,\n",
      "       1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 0, 1, 1, 2, 1, 1, 3, 2, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1,\n",
      "       1, 1, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 2, 2, 2, 2, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 3, 1, 2, 1, 2, 1, 1,\n",
      "       1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 1, 1, 3, 1, 2, 1, 1, 2, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 1, 3, 0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 2, 1,\n",
      "       1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2,\n",
      "       1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 0, 2, 2, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
      "       0, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1,\n",
      "       2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1, 1, 0, 2, 1, 0,\n",
      "       1, 2, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1,\n",
      "       2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2,\n",
      "       1, 2, 1, 2, 1, 2, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1,\n",
      "       1, 2, 2, 0, 2, 2, 0, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1,\n",
      "       3, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 3, 1, 1, 0, 1,\n",
      "       1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1,\n",
      "       2, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 3, 1, 2, 1, 1, 1,\n",
      "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 2, 1,\n",
      "       1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1,\n",
      "       2, 0, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1,\n",
      "       2, 1, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 2, 3, 2, 1, 2, 1, 1, 2, 1, 1,\n",
      "       2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2,\n",
      "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
      "       1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 2,\n",
      "       1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 2, 2,\n",
      "       2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2,\n",
      "       1, 0, 1, 1, 2, 2]), y_true=array([1, 2, 2, 2, 2, 0, 0, 0, 1, 3, 1, 0, 2, 2, 2, 1, 1, 1, 1, 3, 3, 2,\n",
      "       2, 3, 1, 2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 3, 2, 1, 1, 2, 2, 1, 1, 2,\n",
      "       0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1, 0, 3, 3, 1, 0, 3,\n",
      "       0, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 3, 3,\n",
      "       2, 3, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 1, 0, 1, 1, 2, 3, 3, 2, 2, 3,\n",
      "       1, 1, 1, 3, 1, 0, 2, 1, 0, 3, 0, 3, 3, 1, 2, 1, 1, 1, 2, 0, 2, 2,\n",
      "       1, 1, 0, 2, 1, 3, 3, 0, 2, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 2, 2, 2, 1, 0, 3, 1, 1, 1, 2, 3, 0, 1, 2, 1, 1, 1, 0, 1, 1,\n",
      "       3, 0, 1, 3, 1, 1, 0, 2, 2, 2, 1, 1, 2, 3, 1, 2, 2, 2, 1, 1, 2, 1,\n",
      "       0, 3, 2, 3, 1, 0, 2, 1, 2, 3, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1,\n",
      "       1, 1, 3, 1, 1, 2, 2, 1, 1, 2, 2, 3, 2, 3, 1, 3, 1, 3, 1, 3, 2, 3,\n",
      "       2, 2, 2, 3, 1, 1, 1, 1, 2, 2, 2, 3, 1, 2, 1, 0, 2, 2, 2, 0, 1, 1,\n",
      "       1, 3, 0, 1, 3, 2, 3, 1, 0, 1, 3, 3, 2, 3, 1, 1, 1, 2, 1, 2, 0, 1,\n",
      "       0, 3, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1, 1, 3,\n",
      "       3, 2, 3, 0, 3, 0, 1, 0, 3, 0, 3, 0, 1, 1, 1, 3, 1, 3, 1, 3, 0, 0,\n",
      "       1, 1, 3, 0, 2, 0, 1, 2, 2, 0, 1, 1, 3, 2, 1, 2, 3, 3, 2, 3, 2, 2,\n",
      "       1, 0, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 1, 1, 3, 2, 1, 3, 2, 0, 1,\n",
      "       2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 1, 2, 2, 2, 0, 3, 1, 1, 0, 1, 1, 0,\n",
      "       2, 3, 0, 0, 0, 2, 3, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1,\n",
      "       2, 1, 2, 1, 3, 3, 2, 1, 1, 1, 0, 3, 3, 0, 1, 1, 3, 2, 1, 2, 3, 0,\n",
      "       2, 0, 1, 3, 1, 1, 2, 2, 2, 1, 1, 3, 1, 3, 1, 1, 0, 1, 1, 2, 1, 2,\n",
      "       1, 2, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 1, 3, 1, 1, 2, 2, 2, 1, 3, 1,\n",
      "       1, 3, 0, 2, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 3, 1,\n",
      "       0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 3, 1, 2, 1,\n",
      "       3, 2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 3, 0, 3, 2, 2, 2, 3, 2, 0, 3,\n",
      "       1, 2, 1, 0, 2, 3, 1, 1, 0, 1, 3, 1, 0, 1, 2, 3, 1, 1, 3, 3, 1, 1,\n",
      "       0, 1, 0, 3, 1, 3, 1, 0, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1,\n",
      "       2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 3, 2, 0, 3, 2, 2, 1, 3, 2,\n",
      "       2, 1, 1, 3, 2, 2, 3, 2, 1, 1, 3, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1,\n",
      "       1, 2, 1, 2, 3, 3, 3, 2, 2, 3, 2, 1, 1, 0, 1, 1, 1, 2, 2, 3, 2, 1,\n",
      "       1, 0, 2, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 2, 3, 1,\n",
      "       2, 3, 1, 1, 1, 2, 1, 2, 0, 1, 0, 3, 2, 3, 2, 1, 1, 3, 1, 1, 0, 1,\n",
      "       2, 3, 1, 3, 1, 1, 3, 1, 1, 3, 0, 0, 3, 2, 3, 1, 2, 1, 0, 2, 0, 2,\n",
      "       1, 1, 3, 1, 2, 3, 0, 1, 1, 3, 1, 0, 3, 2, 1, 1, 3, 2, 2, 1, 1, 1,\n",
      "       1, 3, 1, 0, 2, 0, 0, 1, 3, 3, 1, 3, 0, 1, 1, 0, 2, 0, 3, 1, 1, 2,\n",
      "       1, 2, 1, 1, 3, 1, 3, 3, 1, 1, 1, 1, 0, 1, 2, 2, 2, 1, 2, 0, 2, 2,\n",
      "       2, 1, 1, 2, 1, 2, 2, 1, 3, 0, 0, 3, 1, 1, 2, 1, 3, 0, 0, 2, 3, 2,\n",
      "       2, 0, 1, 3, 2, 2]), y_probabilities=None, names=None))\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf_result = svm_tfidf_pipeline.run()\n",
    "print(svm_tfidf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_kwargs = {\n",
    "    \"max_features\": 10000\n",
    "}\n",
    "\n",
    "xgb_kwargs = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": 7\n",
    "}\n",
    "\n",
    "evaluation_filename_xgb_tdidf = \"xgb_tfidf_evaluation.json\"\n",
    "\n",
    "xgb_tfidf_pipeline = SklearnClassificationPipeline(\n",
    "    dataset_name=\"clarin-pl/polemo2-official\",\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"target\",\n",
    "    output_path=output_path,\n",
    "    classifier=XGBClassifier,\n",
    "    vectorizer=TfidfVectorizer,\n",
    "    evaluation_filename=evaluation_filename_xgb_tdidf,\n",
    "    classifier_kwargs=xgb_kwargs,\n",
    "    embedding_kwargs=embeddings_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: pol_emo2/all_text\n",
      "Reusing dataset pol_emo2 (/Users/mariuszkossakowski/.cache/huggingface/datasets/clarin-pl___pol_emo2/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50a2c8e31e264d1fab42ebb200b0d941"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: pol_emo2/all_text\n",
      "Reusing dataset pol_emo2 (/Users/mariuszkossakowski/.cache/huggingface/datasets/clarin-pl___pol_emo2/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e05aa544793149fd88f38f786c27d1dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:58:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "TextClassificationEvaluationResults(accuracy=0.7573170731707317, f1_macro=0.7383632851951776, f1_micro=0.7573170731707317, f1_weighted=0.7531105273460682, recall_macro=0.7279708041839421, recall_micro=0.7573170731707317, recall_weighted=0.7573170731707317, precision_macro=0.7527270564328854, precision_micro=0.7573170731707317, precision_weighted=0.7526286151229844, classes={0: {'precision': 0.9722222222222222, 'recall': 0.8898305084745762, 'f1': 0.9292035398230089, 'support': 118}, 1: {'precision': 0.7745358090185677, 'recall': 0.8613569321533924, 'f1': 0.8156424581005588, 'support': 339}, 2: {'precision': 0.746606334841629, 'recall': 0.7268722466960352, 'f1': 0.7366071428571428, 'support': 227}, 3: {'precision': 0.5175438596491229, 'recall': 0.4338235294117647, 'f1': 0.47200000000000003, 'support': 136}}, data=Predictions(y_pred=array([1, 3, 2, 2, 3, 0, 0, 0, 1, 3, 1, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2,\n",
      "       2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 3, 1, 1, 2, 1, 1, 3,\n",
      "       0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 1, 2, 2, 1, 2, 2, 2, 3, 3, 2, 0, 1,\n",
      "       0, 1, 0, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 0, 2, 3, 1, 1, 1, 2, 1, 1,\n",
      "       3, 1, 0, 1, 2, 3, 1, 1, 2, 1, 3, 2, 3, 0, 1, 1, 2, 3, 2, 2, 2, 3,\n",
      "       1, 1, 1, 3, 1, 0, 2, 1, 0, 3, 0, 2, 3, 1, 2, 1, 1, 2, 2, 0, 2, 2,\n",
      "       1, 1, 0, 2, 1, 2, 1, 0, 2, 1, 1, 3, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 2, 2, 2, 1, 0, 3, 1, 1, 1, 3, 3, 0, 1, 1, 1, 1, 1, 2, 1, 1,\n",
      "       3, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 2, 3, 1, 1, 2, 2, 1, 1, 2, 1,\n",
      "       0, 2, 2, 1, 1, 0, 1, 1, 2, 3, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1,\n",
      "       1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 2, 2, 3, 1, 1, 3, 2, 1, 1, 2, 3,\n",
      "       2, 1, 3, 3, 1, 1, 3, 2, 2, 2, 2, 3, 1, 2, 3, 0, 2, 2, 3, 0, 1, 1,\n",
      "       1, 3, 0, 1, 1, 2, 1, 1, 0, 1, 3, 2, 1, 1, 1, 1, 1, 3, 1, 3, 1, 3,\n",
      "       0, 3, 2, 1, 2, 2, 1, 3, 2, 2, 1, 1, 2, 3, 1, 0, 2, 1, 2, 1, 2, 3,\n",
      "       3, 3, 1, 0, 1, 0, 1, 0, 3, 0, 3, 0, 2, 1, 1, 3, 1, 1, 1, 2, 2, 0,\n",
      "       1, 1, 3, 0, 2, 0, 1, 3, 2, 0, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 2, 2,\n",
      "       1, 0, 2, 1, 1, 0, 1, 1, 1, 3, 2, 3, 2, 1, 1, 1, 2, 1, 3, 2, 0, 3,\n",
      "       2, 1, 2, 1, 2, 1, 2, 2, 1, 3, 1, 2, 2, 1, 0, 3, 1, 1, 0, 1, 1, 0,\n",
      "       2, 3, 0, 0, 0, 2, 3, 1, 1, 3, 3, 2, 1, 3, 1, 1, 1, 1, 1, 3, 0, 1,\n",
      "       2, 3, 2, 1, 3, 2, 2, 1, 1, 1, 0, 1, 3, 0, 1, 1, 1, 2, 1, 2, 2, 0,\n",
      "       1, 0, 1, 2, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 0, 1, 3, 3, 1, 2,\n",
      "       1, 3, 1, 3, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 2, 1, 3, 2, 3, 1, 1, 1,\n",
      "       1, 2, 0, 3, 0, 1, 1, 0, 2, 1, 3, 1, 1, 1, 0, 1, 1, 2, 1, 2, 2, 1,\n",
      "       0, 1, 2, 0, 3, 2, 0, 0, 1, 2, 1, 3, 1, 2, 3, 2, 2, 0, 3, 1, 2, 1,\n",
      "       2, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2, 2, 2,\n",
      "       1, 2, 1, 0, 2, 2, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 3, 1, 1, 2, 1, 1,\n",
      "       0, 1, 2, 1, 1, 3, 2, 0, 2, 1, 3, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1,\n",
      "       1, 1, 0, 0, 0, 3, 1, 2, 1, 1, 1, 0, 2, 1, 2, 0, 1, 3, 2, 1, 3, 2,\n",
      "       2, 2, 3, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 0, 1, 3, 1, 0, 1, 1, 3, 3,\n",
      "       1, 0, 2, 2, 3, 2, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 2, 3, 2, 2, 1,\n",
      "       2, 0, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1,\n",
      "       2, 3, 1, 1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0, 1,\n",
      "       2, 1, 1, 1, 2, 1, 3, 2, 1, 1, 0, 0, 3, 2, 1, 1, 2, 1, 0, 3, 1, 2,\n",
      "       1, 1, 3, 1, 1, 3, 0, 1, 1, 3, 1, 0, 3, 2, 1, 1, 3, 2, 2, 1, 1, 1,\n",
      "       1, 3, 1, 0, 2, 0, 1, 2, 2, 1, 1, 1, 0, 1, 1, 0, 2, 0, 3, 1, 1, 2,\n",
      "       1, 1, 1, 1, 3, 1, 3, 3, 1, 3, 1, 1, 0, 1, 2, 2, 2, 1, 2, 0, 2, 3,\n",
      "       2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 0, 0, 2, 1, 2,\n",
      "       3, 0, 1, 1, 2, 1]), y_true=array([1, 2, 2, 2, 2, 0, 0, 0, 1, 3, 1, 0, 2, 2, 2, 1, 1, 1, 1, 3, 3, 2,\n",
      "       2, 3, 1, 2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 3, 2, 1, 1, 2, 2, 1, 1, 2,\n",
      "       0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1, 0, 3, 3, 1, 0, 3,\n",
      "       0, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 3, 3,\n",
      "       2, 3, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 1, 0, 1, 1, 2, 3, 3, 2, 2, 3,\n",
      "       1, 1, 1, 3, 1, 0, 2, 1, 0, 3, 0, 3, 3, 1, 2, 1, 1, 1, 2, 0, 2, 2,\n",
      "       1, 1, 0, 2, 1, 3, 3, 0, 2, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 2, 2, 2, 1, 0, 3, 1, 1, 1, 2, 3, 0, 1, 2, 1, 1, 1, 0, 1, 1,\n",
      "       3, 0, 1, 3, 1, 1, 0, 2, 2, 2, 1, 1, 2, 3, 1, 2, 2, 2, 1, 1, 2, 1,\n",
      "       0, 3, 2, 3, 1, 0, 2, 1, 2, 3, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1,\n",
      "       1, 1, 3, 1, 1, 2, 2, 1, 1, 2, 2, 3, 2, 3, 1, 3, 1, 3, 1, 3, 2, 3,\n",
      "       2, 2, 2, 3, 1, 1, 1, 1, 2, 2, 2, 3, 1, 2, 1, 0, 2, 2, 2, 0, 1, 1,\n",
      "       1, 3, 0, 1, 3, 2, 3, 1, 0, 1, 3, 3, 2, 3, 1, 1, 1, 2, 1, 2, 0, 1,\n",
      "       0, 3, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1, 1, 3,\n",
      "       3, 2, 3, 0, 3, 0, 1, 0, 3, 0, 3, 0, 1, 1, 1, 3, 1, 3, 1, 3, 0, 0,\n",
      "       1, 1, 3, 0, 2, 0, 1, 2, 2, 0, 1, 1, 3, 2, 1, 2, 3, 3, 2, 3, 2, 2,\n",
      "       1, 0, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 1, 1, 3, 2, 1, 3, 2, 0, 1,\n",
      "       2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 1, 2, 2, 2, 0, 3, 1, 1, 0, 1, 1, 0,\n",
      "       2, 3, 0, 0, 0, 2, 3, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1,\n",
      "       2, 1, 2, 1, 3, 3, 2, 1, 1, 1, 0, 3, 3, 0, 1, 1, 3, 2, 1, 2, 3, 0,\n",
      "       2, 0, 1, 3, 1, 1, 2, 2, 2, 1, 1, 3, 1, 3, 1, 1, 0, 1, 1, 2, 1, 2,\n",
      "       1, 2, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 1, 3, 1, 1, 2, 2, 2, 1, 3, 1,\n",
      "       1, 3, 0, 2, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 3, 1,\n",
      "       0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 3, 1, 2, 1,\n",
      "       3, 2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 3, 0, 3, 2, 2, 2, 3, 2, 0, 3,\n",
      "       1, 2, 1, 0, 2, 3, 1, 1, 0, 1, 3, 1, 0, 1, 2, 3, 1, 1, 3, 3, 1, 1,\n",
      "       0, 1, 0, 3, 1, 3, 1, 0, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1,\n",
      "       2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 3, 2, 0, 3, 2, 2, 1, 3, 2,\n",
      "       2, 1, 1, 3, 2, 2, 3, 2, 1, 1, 3, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1,\n",
      "       1, 2, 1, 2, 3, 3, 3, 2, 2, 3, 2, 1, 1, 0, 1, 1, 1, 2, 2, 3, 2, 1,\n",
      "       1, 0, 2, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 2, 3, 1,\n",
      "       2, 3, 1, 1, 1, 2, 1, 2, 0, 1, 0, 3, 2, 3, 2, 1, 1, 3, 1, 1, 0, 1,\n",
      "       2, 3, 1, 3, 1, 1, 3, 1, 1, 3, 0, 0, 3, 2, 3, 1, 2, 1, 0, 2, 0, 2,\n",
      "       1, 1, 3, 1, 2, 3, 0, 1, 1, 3, 1, 0, 3, 2, 1, 1, 3, 2, 2, 1, 1, 1,\n",
      "       1, 3, 1, 0, 2, 0, 0, 1, 3, 3, 1, 3, 0, 1, 1, 0, 2, 0, 3, 1, 1, 2,\n",
      "       1, 2, 1, 1, 3, 1, 3, 3, 1, 1, 1, 1, 0, 1, 2, 2, 2, 1, 2, 0, 2, 2,\n",
      "       2, 1, 1, 2, 1, 2, 2, 1, 3, 0, 0, 3, 1, 1, 2, 1, 3, 0, 0, 2, 3, 2,\n",
      "       2, 0, 1, 3, 2, 2]), y_probabilities=None, names=None))\n"
     ]
    }
   ],
   "source": [
    "xgb_tfidf_result = xgb_tfidf_pipeline.run()\n",
    "print(xgb_tfidf_pipeline.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "methods = [\"AdaBoost\", \"SVM\", \"XGBoost\"]\n",
    "f1_scores = [adaboost_tfidf_result.f1_macro, svm_tfidf_result.f1_macro,\n",
    "             xgb_tfidf_result.f1_macro]\n",
    "results_df = pd.DataFrame(data={\"method\": methods, \"f1\": f1_scores})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(data=results_df, x=\"method\", y=\"f1\")\n",
    "plt.title(\"F1 scores for three different classifiers\", fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this very simple experiment, the XGBoost turned out to be the best. Its way to learn basing on gradients of previous classifiers could be decisive."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}